{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-citation counts computed and stored successfully.\n",
      "All data uploaded to the relational database successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "# Function to parse a single .abs file\n",
    "def parse_abs_data(abs_data):\n",
    "    patterns = {\n",
    "        'paper_id': r'Paper: (.+)',\n",
    "        'authors': r'Authors: (.+)',\n",
    "        'title': r'Title: (.+)',\n",
    "        'comments': r'Comments: (.+)',\n",
    "        'subj_class': r'Subj-class: (.+)',\n",
    "        'journal_ref': r'Journal-ref: (.+)',\n",
    "        'abstract': r'\\n\\\\\\\\\\n ([\\s\\S]+?)\\n\\\\\\\\\\n',\n",
    "    }\n",
    "    return {key: re.search(pattern, abs_data).group(1).strip() if re.search(pattern, abs_data) else None\n",
    "            for key, pattern in patterns.items()}\n",
    "\n",
    "# Relational Database Uploader class\n",
    "class RelationalDatabaseUploader:\n",
    "    def __init__(self, db_path):\n",
    "        self.connection = sqlite3.connect(db_path)\n",
    "        self.cursor = self.connection.cursor()\n",
    "        self._create_tables()\n",
    "\n",
    "    def _create_tables(self):\n",
    "        # Create tables for papers and citations\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS papers (\n",
    "            paper_id TEXT PRIMARY KEY,\n",
    "            title TEXT,\n",
    "            authors TEXT,\n",
    "            comments TEXT,\n",
    "            subj_class TEXT,\n",
    "            journal_ref TEXT,\n",
    "            abstract TEXT\n",
    "        )\"\"\")\n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS citations (\n",
    "            from_paper_id TEXT,\n",
    "            to_paper_id TEXT,\n",
    "            PRIMARY KEY (from_paper_id, to_paper_id),\n",
    "            FOREIGN KEY (from_paper_id) REFERENCES papers(paper_id),\n",
    "            FOREIGN KEY (to_paper_id) REFERENCES papers(paper_id)\n",
    "        )\"\"\")\n",
    "        \n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS paper_dates (\n",
    "            paper_id TEXT PRIMARY KEY,\n",
    "            publication_date DATE NOT NULL,\n",
    "            FOREIGN KEY (paper_id) REFERENCES papers(paper_id)\n",
    "        )\"\"\")\n",
    "        \n",
    "        self.cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS co_citations (\n",
    "            paper_1_id TEXT,\n",
    "            paper_2_id TEXT,\n",
    "            co_citation_count INTEGER,\n",
    "            PRIMARY KEY (paper_1_id, paper_2_id),\n",
    "            FOREIGN KEY (paper_1_id) REFERENCES papers(paper_id),\n",
    "            FOREIGN KEY (paper_2_id) REFERENCES papers(paper_id)\n",
    "        )\"\"\")\n",
    "\n",
    "        self.connection.commit()\n",
    "\n",
    "    def insert_paper(self, parsed_data):\n",
    "        query = \"\"\"\n",
    "        INSERT OR REPLACE INTO papers (paper_id, title, authors, comments, subj_class, journal_ref, abstract)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query, (\n",
    "            parsed_data.get('paper_id'),\n",
    "            parsed_data.get('title'),\n",
    "            parsed_data.get('authors'),\n",
    "            parsed_data.get('comments'),\n",
    "            parsed_data.get('subj_class'),\n",
    "            parsed_data.get('journal_ref'),\n",
    "            parsed_data.get('abstract'),\n",
    "        ))\n",
    "        self.connection.commit()\n",
    "\n",
    "    def insert_citation(self, from_node, to_node):\n",
    "        query = \"\"\"\n",
    "        INSERT OR IGNORE INTO citations (from_paper_id, to_paper_id)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query, (from_node, to_node))\n",
    "        self.connection.commit()\n",
    "        \n",
    "    def insert_paper_date(self, paper_id, publication_date):\n",
    "        query = \"\"\"\n",
    "        INSERT OR IGNORE INTO paper_dates (paper_id, publication_date)\n",
    "        VALUES (?, ?)\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query, (paper_id, publication_date))\n",
    "        self.connection.commit()\n",
    "    \n",
    "    \n",
    "    def insert_co_citation(self, paper_1_id, paper_2_id, co_citation_count):\n",
    "        query = \"\"\"\n",
    "        INSERT OR REPLACE INTO co_citations (paper_1_id, paper_2_id, co_citation_count)\n",
    "        VALUES (?, ?, ?)\n",
    "        \"\"\"\n",
    "        self.cursor.execute(query, (paper_1_id, paper_2_id, co_citation_count))\n",
    "        self.connection.commit()\n",
    "\n",
    "    def close(self):\n",
    "        self.connection.close()\n",
    "\n",
    "# Function to process all .abs files and create rows in the database\n",
    "def process_all_abs_files(root_folder, db_uploader):\n",
    "    for year_folder in os.listdir(root_folder):\n",
    "        year_path = os.path.join(root_folder, year_folder)\n",
    "        if os.path.isdir(year_path) and year_folder.isdigit():\n",
    "            for file_name in os.listdir(year_path):\n",
    "                if file_name.endswith(\".abs\"):\n",
    "                    file_path = os.path.join(year_path, file_name)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        abs_data = file.read()\n",
    "                        parsed_data = parse_abs_data(abs_data)\n",
    "                        # Remove leading zeros from filename\n",
    "                        parsed_data['paper_id'] = str(int(file_name.replace('.abs', '')))\n",
    "                        db_uploader.insert_paper(parsed_data)\n",
    "                        print(f\"Inserted paper: {parsed_data['paper_id']}\")\n",
    "\n",
    "# Function to read and parse Cit-HepTh.txt and create edges in the database\n",
    "def create_edges_from_file(file_path, db_uploader):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            from_node, to_node = line.strip().split()\n",
    "            db_uploader.insert_citation(from_node, to_node)\n",
    "            print(f\"Inserted citation: {from_node} -> {to_node}\")\n",
    "\n",
    "\n",
    "# Function to process cit-HepTh-dates.txt and create the paper_dates table\n",
    "def process_dates_file(file_path, db_uploader):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            paper_id, publication_date = line.strip().split()\n",
    "            if paper_id.startswith(\"11\"):\n",
    "                paper_id = paper_id[2:]\n",
    "            db_uploader.insert_paper_date(str(int(paper_id)), publication_date)\n",
    "            print(f\"Inserted date for paper: {paper_id} -> {publication_date}\")\n",
    "\n",
    "# Function to compute and populate co-citation counts\n",
    "def compute_and_store_co_citation_counts(db_uploader):\n",
    "    # Query to compute co-citation counts\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        c1.to_paper_id AS paper_1_id,\n",
    "        c2.to_paper_id AS paper_2_id,\n",
    "        COUNT(DISTINCT c1.from_paper_id) AS co_citation_count\n",
    "    FROM \n",
    "        citations c1\n",
    "    JOIN \n",
    "        citations c2 ON c1.from_paper_id = c2.from_paper_id\n",
    "    WHERE \n",
    "        c1.to_paper_id < c2.to_paper_id  -- Avoid duplicate pairs\n",
    "    GROUP BY \n",
    "        c1.to_paper_id, c2.to_paper_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query to compute co-citations\n",
    "    db_uploader.cursor.execute(query)\n",
    "    co_citation_data = db_uploader.cursor.fetchall()\n",
    "    \n",
    "    # Insert co-citation counts into the co_citations table\n",
    "    for paper_1_id, paper_2_id, co_citation_count in co_citation_data:\n",
    "        db_uploader.insert_co_citation(paper_1_id, paper_2_id, co_citation_count)\n",
    "\n",
    "    print(\"Co-citation counts computed and stored successfully.\")\n",
    "\n",
    "# Usage\n",
    "root_folder = "./cit-HepTh-abstracts"\n",
    "db_uploader = RelationalDatabaseUploader(\"papers.db\")\n",
    "\n",
    "# Process papers and citations\n",
    "process_all_abs_files(root_folder, db_uploader)\n",
    "create_edges_from_file(\"./cit-HepTh.txt\", db_uploader)\n",
    "\n",
    "process_dates_file('./CS6400-project/cit-HepTh-dates.txt', db_uploader)\n",
    "\n",
    "# Compute and store co-citation counts\n",
    "compute_and_store_co_citation_counts(db_uploader)\n",
    "\n",
    "\n",
    "db_uploader.close()\n",
    "print(\"All data uploaded to the relational database successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6422",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
